{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy NLP model\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"ner\", \"textcat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "\n",
    "    features = {\n",
    "        \"bias\": 1.0,\n",
    "        \"lemma\": sent[i].lemma_,\n",
    "        \"pos\": sent[i].pos_,\n",
    "        \"tag\": sent[i].tag_,\n",
    "        \"dep\": sent[i].dep_,\n",
    "        \"shape\": sent[i].shape_,\n",
    "        \"is_alpha\": sent[i].is_alpha,\n",
    "        \"is_stop\": sent[i].is_stop,\n",
    "        \"is_title\": sent[i].is_title,\n",
    "        \"like_num\": sent[i].line_num,\n",
    "        \"is__left_punct\": sent[i].is_left_punct,\n",
    "        \"is__right_punct\": sent[i].is_right_punct,\n",
    "    }\n",
    "    if i > 0:\n",
    "        features.update(\n",
    "            {\n",
    "                \"-1:lemma\": sent[i - 1].lemma_,\n",
    "                \"-1:pos\": sent[i - 1].pos_,\n",
    "                \"-1:tag\": sent[i - 1].tag_,\n",
    "                \"-1:dep\": sent[i - 1].dep_,\n",
    "                \"-1:shape\": sent[i - 1].shape_,\n",
    "                \"-1:is_alpha\": sent[i - 1].is_alpha,\n",
    "                \"-1:is_stop\": sent[i - 1].is_stop,\n",
    "                \"-1:is_title\": sent[i - 1].is_title,\n",
    "                \"-1:like_num\": sent[i - 1].line_num,\n",
    "                \"-1:is_left_punct\": sent[i - 1].is_left_punct,\n",
    "                \"-1:is_right_punct\": sent[i - 1].is_right_punct,\n",
    "            }\n",
    "        )\n",
    "        if i > 1:\n",
    "            features.update(\n",
    "                {\n",
    "                    \"-2:lemma\": sent[i - 2].lemma_,\n",
    "                    \"-2:pos\": sent[i - 2].pos_,\n",
    "                    \"-2:tag\": sent[i - 2].tag_,\n",
    "                    \"-2:dep\": sent[i - 2].dep_,\n",
    "                    \"-2:shape\": sent[i - 2].shape_,\n",
    "                    \"-2:is_alpha\": sent[i - 2].is_alpha,\n",
    "                    \"-2:is_stop\": sent[i - 2].is_stop,\n",
    "                    \"-2:is_title\": sent[i - 2].is_title,\n",
    "                    \"-2:like_num\": sent[i - 2].line_num,\n",
    "                    \"-2:is_left_punct\": sent[i - 2].is_left_punct,\n",
    "                    \"-2:is_right_punct\": sent[i - 2].is_right_punct,\n",
    "                }\n",
    "            )\n",
    "    else:\n",
    "        features[\"BOS\"] = True\n",
    "\n",
    "    if i < len(sent) - 1:\n",
    "        features.update(\n",
    "            {\n",
    "                \"+1:lemma\": sent[i + 1].lemma_,\n",
    "                \"+1:pos\": sent[i + 1].pos_,\n",
    "                \"+1:tag\": sent[i + 1].tag_,\n",
    "                \"+1:dep\": sent[i + 1].dep_,\n",
    "                \"+1:shape\": sent[i + 1].shape_,\n",
    "                \"+1:is_alpha\": sent[i + 1].is_alpha,\n",
    "                \"+1:is_stop\": sent[i + 1].is_stop,\n",
    "                \"+1:is_title\": sent[i + 1].is_title,\n",
    "                \"+1:like_num\": sent[i + 1].line_num,\n",
    "                \"+1:is_left_punct\": sent[i + 1].is_left_punct,\n",
    "                \"+1:is_right_punct\": sent[i + 1].is_right_punct,\n",
    "            }\n",
    "        )\n",
    "        if i < len(sent) - 2:\n",
    "            features.update(\n",
    "                {\n",
    "                    \"+2:lemma\": sent[i + 2].lemma_,\n",
    "                    \"+2:pos\": sent[i + 2].pos_,\n",
    "                    \"+2:tag\": sent[i + 2].tag_,\n",
    "                    \"+2:dep\": sent[i + 2].dep_,\n",
    "                    \"+2:shape\": sent[i + 2].shape_,\n",
    "                    \"+2:is_alpha\": sent[i + 2].is_alpha,\n",
    "                    \"+2:is_stop\": sent[i + 2].is_stop,\n",
    "                    \"+2:is_title\": sent[i + 2].is_title,\n",
    "                    \"+2:like_num\": sent[i + 2].line_num,\n",
    "                    \"+2:is_right_punct\": sent[i + 2].is_left_punct,\n",
    "                    \"+2:is_right_punct\": sent[i + 2].is_right_punct,\n",
    "                }\n",
    "            )\n",
    "    else:\n",
    "        features[\"EOS\"] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "training_data = pd.read_pickle(\"../data/interim/crf_training_data.pickle\")\n",
    "test_data = pd.read_pickle(\"../data/interim/crf_test_data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# have spacy parse the input string with the full pipeline to generate features this will take some time\n",
    "training_data[\"input\"] = list(nlp.pipe(training_data[\"input\"].astype('unicode').values, batch_size=50))\n",
    "\n",
    "test_data[\"input\"] = list(nlp.pipe(test_data[\"input\"].astype('unicode').values, batch_size=50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_training_features = training_data[\"input\"].apply(lambda doc: [word2features(doc,i) for i in range(len(doc))])\n",
    "                                                  \n",
    "crf_test_features = test_data[\"input\"].apply(lambda doc: [word2features(doc,i) for i in range(len(doc))])                                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_training_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_training_features.to_pickle(\"../data/interim/crf_training_features.pickle\")\n",
    "crf_test_features.to_pickle(\"../data/interim/crf_test_features.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
