{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy NLP model\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"ner\", \"textcat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "\n",
    "    features = {\n",
    "        \"bias\": 1.0,\n",
    "        \"lemma\": sent[i].lemma_,\n",
    "        \"pos\": sent[i].pos_,\n",
    "        \"tag\": sent[i].tag_,\n",
    "        \"dep\": sent[i].dep_,\n",
    "        \"shape\": sent[i].shape_,\n",
    "        \"is_alpha\": sent[i].is_alpha,\n",
    "        \"is_stop\": sent[i].is_stop,\n",
    "        \"is_title\": sent[i].is_title,\n",
    "        \"is_punct\": sent[i].is_punct,\n",
    "    }\n",
    "    if i > 0:\n",
    "        features.update(\n",
    "            {\n",
    "                \"-1:lemma\": sent[i - 1].lemma_,\n",
    "                \"-1:pos\": sent[i - 1].pos_,\n",
    "                \"-1:tag\": sent[i - 1].tag_,\n",
    "                \"-1:dep\": sent[i - 1].dep_,\n",
    "                \"-1:shape\": sent[i - 1].shape_,\n",
    "                \"-1:is_alpha\": sent[i - 1].is_alpha,\n",
    "                \"-1:is_stop\": sent[i - 1].is_stop,\n",
    "                \"-1:is_title\": sent[i - 1].is_title,\n",
    "                \"-1:is_left_punct\": sent[i - 1].is_left_punct,\n",
    "            }\n",
    "        )\n",
    "        if i > 1:\n",
    "            features.update(\n",
    "                {\n",
    "                    \"-2:lemma\": sent[i - 2].lemma_,\n",
    "                    \"-2:pos\": sent[i - 2].pos_,\n",
    "                    \"-2:tag\": sent[i - 2].tag_,\n",
    "                    \"-2:dep\": sent[i - 2].dep_,\n",
    "                    \"-2:shape\": sent[i - 2].shape_,\n",
    "                    \"-2:is_alpha\": sent[i - 2].is_alpha,\n",
    "                    \"-2:is_stop\": sent[i - 2].is_stop,\n",
    "                    \"-2:is_title\": sent[i - 2].is_title,\n",
    "                    \"-2:is_left_punct\": sent[i - 2].is_left_punct,\n",
    "                }\n",
    "            )\n",
    "    else:\n",
    "        features[\"BOS\"] = True\n",
    "\n",
    "    if i < len(sent) - 1:\n",
    "        features.update(\n",
    "            {\n",
    "                \"+1:lemma\": sent[i + 1].lemma_,\n",
    "                \"+1:pos\": sent[i + 1].pos_,\n",
    "                \"+1:tag\": sent[i + 1].tag_,\n",
    "                \"+1:dep\": sent[i + 1].dep_,\n",
    "                \"+1:shape\": sent[i + 1].shape_,\n",
    "                \"+1:is_alpha\": sent[i + 1].is_alpha,\n",
    "                \"+1:is_stop\": sent[i + 1].is_stop,\n",
    "                \"+1:is_title\": sent[i + 1].is_title,\n",
    "                \"+1:is_right_punct\": sent[i + 1].is_right_punct,\n",
    "            }\n",
    "        )\n",
    "        if i < len(sent) - 2:\n",
    "            features.update(\n",
    "                {\n",
    "                    \"+2:lemma\": sent[i + 2].lemma_,\n",
    "                    \"+2:pos\": sent[i + 2].pos_,\n",
    "                    \"+2:tag\": sent[i + 2].tag_,\n",
    "                    \"+2:dep\": sent[i + 2].dep_,\n",
    "                    \"+2:shape\": sent[i + 2].shape_,\n",
    "                    \"+2:is_alpha\": sent[i + 2].is_alpha,\n",
    "                    \"+2:is_stop\": sent[i + 2].is_stop,\n",
    "                    \"+2:is_title\": sent[i + 2].is_title,\n",
    "                    \"+2:is_right_punct\": sent[i + 2].is_right_punct,\n",
    "                }\n",
    "            )\n",
    "    else:\n",
    "        features[\"EOS\"] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "training_data = pd.read_pickle(\"../data/interim/crf_training_data.pickle\")\n",
    "test_data = pd.read_pickle(\"../data/interim/crf_test_data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>name</th>\n",
       "      <th>qty</th>\n",
       "      <th>range_end</th>\n",
       "      <th>unit</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107273</th>\n",
       "      <td>Freshly grated imported Parmesan cheese, prefe...</td>\n",
       "      <td>Parmesan cheese</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freshly grated imported, preferably parmigiano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58171</th>\n",
       "      <td>1 large sweet potato, peeled and cut into 1/2-...</td>\n",
       "      <td>sweet potato</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large, peeled and cut into 1/2-inch cubes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>Freshly ground black pepper to taste</td>\n",
       "      <td>black pepper</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freshly ground to taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177211</th>\n",
       "      <td>0.25 cup all-purpose flour</td>\n",
       "      <td>all-purpose flour</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cup</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33971</th>\n",
       "      <td>2 2-ounce cans anchovy fillets, packed in oil</td>\n",
       "      <td>anchovy fillets</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ounce</td>\n",
       "      <td>2 2-ounce cans, packed in oil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    input               name  \\\n",
       "index                                                                          \n",
       "107273  Freshly grated imported Parmesan cheese, prefe...    Parmesan cheese   \n",
       "58171   1 large sweet potato, peeled and cut into 1/2-...       sweet potato   \n",
       "6569                 Freshly ground black pepper to taste       black pepper   \n",
       "177211                         0.25 cup all-purpose flour  all-purpose flour   \n",
       "33971       2 2-ounce cans anchovy fillets, packed in oil    anchovy fillets   \n",
       "\n",
       "         qty  range_end   unit  \\\n",
       "index                            \n",
       "107273     0        0.0    NaN   \n",
       "58171      1        0.0    NaN   \n",
       "6569       0        0.0    NaN   \n",
       "177211  0.25        0.0    cup   \n",
       "33971      4        0.0  ounce   \n",
       "\n",
       "                                                  comment  \n",
       "index                                                      \n",
       "107273  Freshly grated imported, preferably parmigiano...  \n",
       "58171           large, peeled and cut into 1/2-inch cubes  \n",
       "6569                              Freshly ground to taste  \n",
       "177211                                                NaN  \n",
       "33971                       2 2-ounce cans, packed in oil  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>name</th>\n",
       "      <th>qty</th>\n",
       "      <th>range_end</th>\n",
       "      <th>unit</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102201</th>\n",
       "      <td>1 cup raw rice</td>\n",
       "      <td>rice</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cup</td>\n",
       "      <td>raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149431</th>\n",
       "      <td>1/2 teaspoon salt</td>\n",
       "      <td>salt</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>teaspoon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50733</th>\n",
       "      <td>1 cup heavy cream</td>\n",
       "      <td>heavy cream</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cup</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66931</th>\n",
       "      <td>2 cloves garlic, peeled and minced</td>\n",
       "      <td>garlic</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>clove</td>\n",
       "      <td>peeled and minced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78296</th>\n",
       "      <td>1/4 cup Marsala wine</td>\n",
       "      <td>Marsala wine</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cup</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     input          name   qty  range_end  \\\n",
       "index                                                                       \n",
       "102201                      1 cup raw rice          rice     1        0.0   \n",
       "149431                   1/2 teaspoon salt          salt   0.5        0.0   \n",
       "50733                    1 cup heavy cream   heavy cream     1        0.0   \n",
       "66931   2 cloves garlic, peeled and minced        garlic     2        0.0   \n",
       "78296                 1/4 cup Marsala wine  Marsala wine  0.25        0.0   \n",
       "\n",
       "            unit            comment  \n",
       "index                                \n",
       "102201       cup                raw  \n",
       "149431  teaspoon                NaN  \n",
       "50733        cup                NaN  \n",
       "66931      clove  peeled and minced  \n",
       "78296        cup                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# have spacy parse the input string with the full pipeline to generate features this will take some time\n",
    "training_data[\"input\"] = list(nlp.pipe(training_data[\"input\"].astype('unicode').values, batch_size=50))\n",
    "\n",
    "test_data[\"input\"] = list(nlp.pipe(test_data[\"input\"].astype('unicode').values, batch_size=50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>name</th>\n",
       "      <th>qty</th>\n",
       "      <th>range_end</th>\n",
       "      <th>unit</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107273</th>\n",
       "      <td>(Freshly, grated, imported, Parmesan, cheese, ...</td>\n",
       "      <td>Parmesan cheese</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freshly grated imported, preferably parmigiano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58171</th>\n",
       "      <td>(1, large, sweet, potato, ,, peeled, and, cut,...</td>\n",
       "      <td>sweet potato</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large, peeled and cut into 1/2-inch cubes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>(Freshly, ground, black, pepper, to, taste)</td>\n",
       "      <td>black pepper</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freshly ground to taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177211</th>\n",
       "      <td>(0.25, cup, all, -, purpose, flour)</td>\n",
       "      <td>all-purpose flour</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cup</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33971</th>\n",
       "      <td>(2, 2-ounce, cans, anchovy, fillets, ,, packed...</td>\n",
       "      <td>anchovy fillets</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ounce</td>\n",
       "      <td>2 2-ounce cans, packed in oil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    input               name  \\\n",
       "index                                                                          \n",
       "107273  (Freshly, grated, imported, Parmesan, cheese, ...    Parmesan cheese   \n",
       "58171   (1, large, sweet, potato, ,, peeled, and, cut,...       sweet potato   \n",
       "6569          (Freshly, ground, black, pepper, to, taste)       black pepper   \n",
       "177211                (0.25, cup, all, -, purpose, flour)  all-purpose flour   \n",
       "33971   (2, 2-ounce, cans, anchovy, fillets, ,, packed...    anchovy fillets   \n",
       "\n",
       "         qty  range_end   unit  \\\n",
       "index                            \n",
       "107273     0        0.0    NaN   \n",
       "58171      1        0.0    NaN   \n",
       "6569       0        0.0    NaN   \n",
       "177211  0.25        0.0    cup   \n",
       "33971      4        0.0  ounce   \n",
       "\n",
       "                                                  comment  \n",
       "index                                                      \n",
       "107273  Freshly grated imported, preferably parmigiano...  \n",
       "58171           large, peeled and cut into 1/2-inch cubes  \n",
       "6569                              Freshly ground to taste  \n",
       "177211                                                NaN  \n",
       "33971                       2 2-ounce cans, packed in oil  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_training_features = training_data[\"input\"].apply(lambda doc: [word2features(doc,i) for i in range(len(doc))])\n",
    "                                                  \n",
    "crf_test_features = test_data[\"input\"].apply(lambda doc: [word2features(doc,i) for i in range(len(doc))])                                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': 1.0,\n",
       "  'lemma': '1.25',\n",
       "  'pos': 'NUM',\n",
       "  'tag': 'CD',\n",
       "  'dep': 'nummod',\n",
       "  'shape': 'd.dd',\n",
       "  'is_alpha': False,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  'BOS': True,\n",
       "  '+1:lemma': 'cup',\n",
       "  '+1:pos': 'NOUN',\n",
       "  '+1:tag': 'NNS',\n",
       "  '+1:dep': 'ROOT',\n",
       "  '+1:shape': 'xxxx',\n",
       "  '+1:is_alpha': True,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': 'cook',\n",
       "  '+2:pos': 'VERB',\n",
       "  '+2:tag': 'VBN',\n",
       "  '+2:dep': 'acl',\n",
       "  '+2:shape': 'xxxx',\n",
       "  '+2:is_alpha': True,\n",
       "  '+2:is_stop': False,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': 'cup',\n",
       "  'pos': 'NOUN',\n",
       "  'tag': 'NNS',\n",
       "  'dep': 'ROOT',\n",
       "  'shape': 'xxxx',\n",
       "  'is_alpha': True,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': '1.25',\n",
       "  '-1:pos': 'NUM',\n",
       "  '-1:tag': 'CD',\n",
       "  '-1:dep': 'nummod',\n",
       "  '-1:shape': 'd.dd',\n",
       "  '-1:is_alpha': False,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '+1:lemma': 'cook',\n",
       "  '+1:pos': 'VERB',\n",
       "  '+1:tag': 'VBN',\n",
       "  '+1:dep': 'acl',\n",
       "  '+1:shape': 'xxxx',\n",
       "  '+1:is_alpha': True,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': 'and',\n",
       "  '+2:pos': 'CCONJ',\n",
       "  '+2:tag': 'CC',\n",
       "  '+2:dep': 'cc',\n",
       "  '+2:shape': 'xxx',\n",
       "  '+2:is_alpha': True,\n",
       "  '+2:is_stop': True,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': 'cook',\n",
       "  'pos': 'VERB',\n",
       "  'tag': 'VBN',\n",
       "  'dep': 'acl',\n",
       "  'shape': 'xxxx',\n",
       "  'is_alpha': True,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': 'cup',\n",
       "  '-1:pos': 'NOUN',\n",
       "  '-1:tag': 'NNS',\n",
       "  '-1:dep': 'ROOT',\n",
       "  '-1:shape': 'xxxx',\n",
       "  '-1:is_alpha': True,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': '1.25',\n",
       "  '-2:pos': 'NUM',\n",
       "  '-2:tag': 'CD',\n",
       "  '-2:dep': 'nummod',\n",
       "  '-2:shape': 'd.dd',\n",
       "  '-2:is_alpha': False,\n",
       "  '-2:is_stop': False,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': 'and',\n",
       "  '+1:pos': 'CCONJ',\n",
       "  '+1:tag': 'CC',\n",
       "  '+1:dep': 'cc',\n",
       "  '+1:shape': 'xxx',\n",
       "  '+1:is_alpha': True,\n",
       "  '+1:is_stop': True,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': 'pureed',\n",
       "  '+2:pos': 'ADJ',\n",
       "  '+2:tag': 'JJ',\n",
       "  '+2:dep': 'conj',\n",
       "  '+2:shape': 'xxxx',\n",
       "  '+2:is_alpha': True,\n",
       "  '+2:is_stop': False,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': 'and',\n",
       "  'pos': 'CCONJ',\n",
       "  'tag': 'CC',\n",
       "  'dep': 'cc',\n",
       "  'shape': 'xxx',\n",
       "  'is_alpha': True,\n",
       "  'is_stop': True,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': 'cook',\n",
       "  '-1:pos': 'VERB',\n",
       "  '-1:tag': 'VBN',\n",
       "  '-1:dep': 'acl',\n",
       "  '-1:shape': 'xxxx',\n",
       "  '-1:is_alpha': True,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': 'cup',\n",
       "  '-2:pos': 'NOUN',\n",
       "  '-2:tag': 'NNS',\n",
       "  '-2:dep': 'ROOT',\n",
       "  '-2:shape': 'xxxx',\n",
       "  '-2:is_alpha': True,\n",
       "  '-2:is_stop': False,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': 'pureed',\n",
       "  '+1:pos': 'ADJ',\n",
       "  '+1:tag': 'JJ',\n",
       "  '+1:dep': 'conj',\n",
       "  '+1:shape': 'xxxx',\n",
       "  '+1:is_alpha': True,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': 'fresh',\n",
       "  '+2:pos': 'ADJ',\n",
       "  '+2:tag': 'JJ',\n",
       "  '+2:dep': 'amod',\n",
       "  '+2:shape': 'xxxx',\n",
       "  '+2:is_alpha': True,\n",
       "  '+2:is_stop': False,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': 'pureed',\n",
       "  'pos': 'ADJ',\n",
       "  'tag': 'JJ',\n",
       "  'dep': 'conj',\n",
       "  'shape': 'xxxx',\n",
       "  'is_alpha': True,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': 'and',\n",
       "  '-1:pos': 'CCONJ',\n",
       "  '-1:tag': 'CC',\n",
       "  '-1:dep': 'cc',\n",
       "  '-1:shape': 'xxx',\n",
       "  '-1:is_alpha': True,\n",
       "  '-1:is_stop': True,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': 'cook',\n",
       "  '-2:pos': 'VERB',\n",
       "  '-2:tag': 'VBN',\n",
       "  '-2:dep': 'acl',\n",
       "  '-2:shape': 'xxxx',\n",
       "  '-2:is_alpha': True,\n",
       "  '-2:is_stop': False,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': 'fresh',\n",
       "  '+1:pos': 'ADJ',\n",
       "  '+1:tag': 'JJ',\n",
       "  '+1:dep': 'amod',\n",
       "  '+1:shape': 'xxxx',\n",
       "  '+1:is_alpha': True,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': 'butternut',\n",
       "  '+2:pos': 'NOUN',\n",
       "  '+2:tag': 'NN',\n",
       "  '+2:dep': 'compound',\n",
       "  '+2:shape': 'xxxx',\n",
       "  '+2:is_alpha': True,\n",
       "  '+2:is_stop': False,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': 'fresh',\n",
       "  'pos': 'ADJ',\n",
       "  'tag': 'JJ',\n",
       "  'dep': 'amod',\n",
       "  'shape': 'xxxx',\n",
       "  'is_alpha': True,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': 'pureed',\n",
       "  '-1:pos': 'ADJ',\n",
       "  '-1:tag': 'JJ',\n",
       "  '-1:dep': 'conj',\n",
       "  '-1:shape': 'xxxx',\n",
       "  '-1:is_alpha': True,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': 'and',\n",
       "  '-2:pos': 'CCONJ',\n",
       "  '-2:tag': 'CC',\n",
       "  '-2:dep': 'cc',\n",
       "  '-2:shape': 'xxx',\n",
       "  '-2:is_alpha': True,\n",
       "  '-2:is_stop': True,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': 'butternut',\n",
       "  '+1:pos': 'NOUN',\n",
       "  '+1:tag': 'NN',\n",
       "  '+1:dep': 'compound',\n",
       "  '+1:shape': 'xxxx',\n",
       "  '+1:is_alpha': True,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': 'squash',\n",
       "  '+2:pos': 'NOUN',\n",
       "  '+2:tag': 'NN',\n",
       "  '+2:dep': 'dobj',\n",
       "  '+2:shape': 'xxxx',\n",
       "  '+2:is_alpha': True,\n",
       "  '+2:is_stop': False,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': 'butternut',\n",
       "  'pos': 'NOUN',\n",
       "  'tag': 'NN',\n",
       "  'dep': 'compound',\n",
       "  'shape': 'xxxx',\n",
       "  'is_alpha': True,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': 'fresh',\n",
       "  '-1:pos': 'ADJ',\n",
       "  '-1:tag': 'JJ',\n",
       "  '-1:dep': 'amod',\n",
       "  '-1:shape': 'xxxx',\n",
       "  '-1:is_alpha': True,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': 'pureed',\n",
       "  '-2:pos': 'ADJ',\n",
       "  '-2:tag': 'JJ',\n",
       "  '-2:dep': 'conj',\n",
       "  '-2:shape': 'xxxx',\n",
       "  '-2:is_alpha': True,\n",
       "  '-2:is_stop': False,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': 'squash',\n",
       "  '+1:pos': 'NOUN',\n",
       "  '+1:tag': 'NN',\n",
       "  '+1:dep': 'dobj',\n",
       "  '+1:shape': 'xxxx',\n",
       "  '+1:is_alpha': True,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': ',',\n",
       "  '+2:pos': 'PUNCT',\n",
       "  '+2:tag': ',',\n",
       "  '+2:dep': 'punct',\n",
       "  '+2:shape': ',',\n",
       "  '+2:is_alpha': False,\n",
       "  '+2:is_stop': False,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': 'squash',\n",
       "  'pos': 'NOUN',\n",
       "  'tag': 'NN',\n",
       "  'dep': 'dobj',\n",
       "  'shape': 'xxxx',\n",
       "  'is_alpha': True,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': 'butternut',\n",
       "  '-1:pos': 'NOUN',\n",
       "  '-1:tag': 'NN',\n",
       "  '-1:dep': 'compound',\n",
       "  '-1:shape': 'xxxx',\n",
       "  '-1:is_alpha': True,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': 'fresh',\n",
       "  '-2:pos': 'ADJ',\n",
       "  '-2:tag': 'JJ',\n",
       "  '-2:dep': 'amod',\n",
       "  '-2:shape': 'xxxx',\n",
       "  '-2:is_alpha': True,\n",
       "  '-2:is_stop': False,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': ',',\n",
       "  '+1:pos': 'PUNCT',\n",
       "  '+1:tag': ',',\n",
       "  '+1:dep': 'punct',\n",
       "  '+1:shape': ',',\n",
       "  '+1:is_alpha': False,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': 'or',\n",
       "  '+2:pos': 'CCONJ',\n",
       "  '+2:tag': 'CC',\n",
       "  '+2:dep': 'cc',\n",
       "  '+2:shape': 'xx',\n",
       "  '+2:is_alpha': True,\n",
       "  '+2:is_stop': True,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': ',',\n",
       "  'pos': 'PUNCT',\n",
       "  'tag': ',',\n",
       "  'dep': 'punct',\n",
       "  'shape': ',',\n",
       "  'is_alpha': False,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': True,\n",
       "  '-1:lemma': 'squash',\n",
       "  '-1:pos': 'NOUN',\n",
       "  '-1:tag': 'NN',\n",
       "  '-1:dep': 'dobj',\n",
       "  '-1:shape': 'xxxx',\n",
       "  '-1:is_alpha': True,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': 'butternut',\n",
       "  '-2:pos': 'NOUN',\n",
       "  '-2:tag': 'NN',\n",
       "  '-2:dep': 'compound',\n",
       "  '-2:shape': 'xxxx',\n",
       "  '-2:is_alpha': True,\n",
       "  '-2:is_stop': False,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': 'or',\n",
       "  '+1:pos': 'CCONJ',\n",
       "  '+1:tag': 'CC',\n",
       "  '+1:dep': 'cc',\n",
       "  '+1:shape': 'xx',\n",
       "  '+1:is_alpha': True,\n",
       "  '+1:is_stop': True,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': '1',\n",
       "  '+2:pos': 'NUM',\n",
       "  '+2:tag': 'CD',\n",
       "  '+2:dep': 'nummod',\n",
       "  '+2:shape': 'd',\n",
       "  '+2:is_alpha': False,\n",
       "  '+2:is_stop': False,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': 'or',\n",
       "  'pos': 'CCONJ',\n",
       "  'tag': 'CC',\n",
       "  'dep': 'cc',\n",
       "  'shape': 'xx',\n",
       "  'is_alpha': True,\n",
       "  'is_stop': True,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': ',',\n",
       "  '-1:pos': 'PUNCT',\n",
       "  '-1:tag': ',',\n",
       "  '-1:dep': 'punct',\n",
       "  '-1:shape': ',',\n",
       "  '-1:is_alpha': False,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': 'squash',\n",
       "  '-2:pos': 'NOUN',\n",
       "  '-2:tag': 'NN',\n",
       "  '-2:dep': 'dobj',\n",
       "  '-2:shape': 'xxxx',\n",
       "  '-2:is_alpha': True,\n",
       "  '-2:is_stop': False,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': '1',\n",
       "  '+1:pos': 'NUM',\n",
       "  '+1:tag': 'CD',\n",
       "  '+1:dep': 'nummod',\n",
       "  '+1:shape': 'd',\n",
       "  '+1:is_alpha': False,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': '10-ounce',\n",
       "  '+2:pos': 'ADJ',\n",
       "  '+2:tag': 'JJ',\n",
       "  '+2:dep': 'amod',\n",
       "  '+2:shape': 'dd-xxxx',\n",
       "  '+2:is_alpha': False,\n",
       "  '+2:is_stop': False,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': '1',\n",
       "  'pos': 'NUM',\n",
       "  'tag': 'CD',\n",
       "  'dep': 'nummod',\n",
       "  'shape': 'd',\n",
       "  'is_alpha': False,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': 'or',\n",
       "  '-1:pos': 'CCONJ',\n",
       "  '-1:tag': 'CC',\n",
       "  '-1:dep': 'cc',\n",
       "  '-1:shape': 'xx',\n",
       "  '-1:is_alpha': True,\n",
       "  '-1:is_stop': True,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': ',',\n",
       "  '-2:pos': 'PUNCT',\n",
       "  '-2:tag': ',',\n",
       "  '-2:dep': 'punct',\n",
       "  '-2:shape': ',',\n",
       "  '-2:is_alpha': False,\n",
       "  '-2:is_stop': False,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': '10-ounce',\n",
       "  '+1:pos': 'ADJ',\n",
       "  '+1:tag': 'JJ',\n",
       "  '+1:dep': 'amod',\n",
       "  '+1:shape': 'dd-xxxx',\n",
       "  '+1:is_alpha': False,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': 'package',\n",
       "  '+2:pos': 'NOUN',\n",
       "  '+2:tag': 'NN',\n",
       "  '+2:dep': 'nmod',\n",
       "  '+2:shape': 'xxxx',\n",
       "  '+2:is_alpha': True,\n",
       "  '+2:is_stop': False,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': '10-ounce',\n",
       "  'pos': 'ADJ',\n",
       "  'tag': 'JJ',\n",
       "  'dep': 'amod',\n",
       "  'shape': 'dd-xxxx',\n",
       "  'is_alpha': False,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': '1',\n",
       "  '-1:pos': 'NUM',\n",
       "  '-1:tag': 'CD',\n",
       "  '-1:dep': 'nummod',\n",
       "  '-1:shape': 'd',\n",
       "  '-1:is_alpha': False,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': 'or',\n",
       "  '-2:pos': 'CCONJ',\n",
       "  '-2:tag': 'CC',\n",
       "  '-2:dep': 'cc',\n",
       "  '-2:shape': 'xx',\n",
       "  '-2:is_alpha': True,\n",
       "  '-2:is_stop': True,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': 'package',\n",
       "  '+1:pos': 'NOUN',\n",
       "  '+1:tag': 'NN',\n",
       "  '+1:dep': 'nmod',\n",
       "  '+1:shape': 'xxxx',\n",
       "  '+1:is_alpha': True,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': 'frozen',\n",
       "  '+2:pos': 'ADJ',\n",
       "  '+2:tag': 'JJ',\n",
       "  '+2:dep': 'amod',\n",
       "  '+2:shape': 'xxxx',\n",
       "  '+2:is_alpha': True,\n",
       "  '+2:is_stop': False,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': 'package',\n",
       "  'pos': 'NOUN',\n",
       "  'tag': 'NN',\n",
       "  'dep': 'nmod',\n",
       "  'shape': 'xxxx',\n",
       "  'is_alpha': True,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': '10-ounce',\n",
       "  '-1:pos': 'ADJ',\n",
       "  '-1:tag': 'JJ',\n",
       "  '-1:dep': 'amod',\n",
       "  '-1:shape': 'dd-xxxx',\n",
       "  '-1:is_alpha': False,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': '1',\n",
       "  '-2:pos': 'NUM',\n",
       "  '-2:tag': 'CD',\n",
       "  '-2:dep': 'nummod',\n",
       "  '-2:shape': 'd',\n",
       "  '-2:is_alpha': False,\n",
       "  '-2:is_stop': False,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': 'frozen',\n",
       "  '+1:pos': 'ADJ',\n",
       "  '+1:tag': 'JJ',\n",
       "  '+1:dep': 'amod',\n",
       "  '+1:shape': 'xxxx',\n",
       "  '+1:is_alpha': True,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': 'squash',\n",
       "  '+2:pos': 'NOUN',\n",
       "  '+2:tag': 'NN',\n",
       "  '+2:dep': 'conj',\n",
       "  '+2:shape': 'xxxx',\n",
       "  '+2:is_alpha': True,\n",
       "  '+2:is_stop': False,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': 'frozen',\n",
       "  'pos': 'ADJ',\n",
       "  'tag': 'JJ',\n",
       "  'dep': 'amod',\n",
       "  'shape': 'xxxx',\n",
       "  'is_alpha': True,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': 'package',\n",
       "  '-1:pos': 'NOUN',\n",
       "  '-1:tag': 'NN',\n",
       "  '-1:dep': 'nmod',\n",
       "  '-1:shape': 'xxxx',\n",
       "  '-1:is_alpha': True,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': '10-ounce',\n",
       "  '-2:pos': 'ADJ',\n",
       "  '-2:tag': 'JJ',\n",
       "  '-2:dep': 'amod',\n",
       "  '-2:shape': 'dd-xxxx',\n",
       "  '-2:is_alpha': False,\n",
       "  '-2:is_stop': False,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': 'squash',\n",
       "  '+1:pos': 'NOUN',\n",
       "  '+1:tag': 'NN',\n",
       "  '+1:dep': 'conj',\n",
       "  '+1:shape': 'xxxx',\n",
       "  '+1:is_alpha': True,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': ',',\n",
       "  '+2:pos': 'PUNCT',\n",
       "  '+2:tag': ',',\n",
       "  '+2:dep': 'punct',\n",
       "  '+2:shape': ',',\n",
       "  '+2:is_alpha': False,\n",
       "  '+2:is_stop': False,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': 'squash',\n",
       "  'pos': 'NOUN',\n",
       "  'tag': 'NN',\n",
       "  'dep': 'conj',\n",
       "  'shape': 'xxxx',\n",
       "  'is_alpha': True,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': 'frozen',\n",
       "  '-1:pos': 'ADJ',\n",
       "  '-1:tag': 'JJ',\n",
       "  '-1:dep': 'amod',\n",
       "  '-1:shape': 'xxxx',\n",
       "  '-1:is_alpha': True,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': 'package',\n",
       "  '-2:pos': 'NOUN',\n",
       "  '-2:tag': 'NN',\n",
       "  '-2:dep': 'nmod',\n",
       "  '-2:shape': 'xxxx',\n",
       "  '-2:is_alpha': True,\n",
       "  '-2:is_stop': False,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': ',',\n",
       "  '+1:pos': 'PUNCT',\n",
       "  '+1:tag': ',',\n",
       "  '+1:dep': 'punct',\n",
       "  '+1:shape': ',',\n",
       "  '+1:is_alpha': False,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False,\n",
       "  '+2:lemma': 'defrost',\n",
       "  '+2:pos': 'VERB',\n",
       "  '+2:tag': 'VBN',\n",
       "  '+2:dep': 'acl',\n",
       "  '+2:shape': 'xxxx',\n",
       "  '+2:is_alpha': True,\n",
       "  '+2:is_stop': False,\n",
       "  '+2:is_title': False,\n",
       "  '+2:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': ',',\n",
       "  'pos': 'PUNCT',\n",
       "  'tag': ',',\n",
       "  'dep': 'punct',\n",
       "  'shape': ',',\n",
       "  'is_alpha': False,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': True,\n",
       "  '-1:lemma': 'squash',\n",
       "  '-1:pos': 'NOUN',\n",
       "  '-1:tag': 'NN',\n",
       "  '-1:dep': 'conj',\n",
       "  '-1:shape': 'xxxx',\n",
       "  '-1:is_alpha': True,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': 'frozen',\n",
       "  '-2:pos': 'ADJ',\n",
       "  '-2:tag': 'JJ',\n",
       "  '-2:dep': 'amod',\n",
       "  '-2:shape': 'xxxx',\n",
       "  '-2:is_alpha': True,\n",
       "  '-2:is_stop': False,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  '+1:lemma': 'defrost',\n",
       "  '+1:pos': 'VERB',\n",
       "  '+1:tag': 'VBN',\n",
       "  '+1:dep': 'acl',\n",
       "  '+1:shape': 'xxxx',\n",
       "  '+1:is_alpha': True,\n",
       "  '+1:is_stop': False,\n",
       "  '+1:is_title': False,\n",
       "  '+1:is_right_punct': False},\n",
       " {'bias': 1.0,\n",
       "  'lemma': 'defrost',\n",
       "  'pos': 'VERB',\n",
       "  'tag': 'VBN',\n",
       "  'dep': 'acl',\n",
       "  'shape': 'xxxx',\n",
       "  'is_alpha': True,\n",
       "  'is_stop': False,\n",
       "  'is_title': False,\n",
       "  'is_punct': False,\n",
       "  '-1:lemma': ',',\n",
       "  '-1:pos': 'PUNCT',\n",
       "  '-1:tag': ',',\n",
       "  '-1:dep': 'punct',\n",
       "  '-1:shape': ',',\n",
       "  '-1:is_alpha': False,\n",
       "  '-1:is_stop': False,\n",
       "  '-1:is_title': False,\n",
       "  '-1:is_left_punct': False,\n",
       "  '-2:lemma': 'squash',\n",
       "  '-2:pos': 'NOUN',\n",
       "  '-2:tag': 'NN',\n",
       "  '-2:dep': 'conj',\n",
       "  '-2:shape': 'xxxx',\n",
       "  '-2:is_alpha': True,\n",
       "  '-2:is_stop': False,\n",
       "  '-2:is_title': False,\n",
       "  '-2:is_left_punct': False,\n",
       "  'EOS': True}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf_training_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_training_features.to_pickle(\"../data/interim/crf_training_features.pickle\")\n",
    "crf_test_features.to_pickle(\"../data/interim/crf_test_features.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
